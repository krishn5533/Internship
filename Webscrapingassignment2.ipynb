{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping assignment2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"d8b5954620ea5afe314b52cf1d5637a2\", element=\"15b96931-00b8-432b-903e-389ab0e484a6\")>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "jobsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element_by_id('qsb-location-sugg')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_class_name('btn')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "company = []\n",
    "locations = []\n",
    "xp = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "xp_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "for x in xp_tag:\n",
    "    xp.append(x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in JobDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Experience\":xp[0:10],\"Location\":locations[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst/Business Analyst-Gurgaon/Bangalor...</td>\n",
       "      <td>India Medtronic Pvt. Ltd,.</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst II</td>\n",
       "      <td>Infobahn Softworld Inc.</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>WEIWO Communication Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Ulsoor)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GCC SERVICES INDIA PRIVATE LIMITED</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Enzen Global Solutions Pvt. Ltd</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Liventus, Inc.</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(2nd Phase JP Nagar)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1                               Business Data Analyst   \n",
       "2                               Business Data Analyst   \n",
       "3   Data Analyst/Business Analyst-Gurgaon/Bangalor...   \n",
       "4                            Business Data Analyst II   \n",
       "5                                        Data Analyst   \n",
       "6                                        Data Analyst   \n",
       "7                                        Data Analyst   \n",
       "8                                        Data Analyst   \n",
       "9                                        Data Analyst   \n",
       "10                                Senior Data Analyst   \n",
       "\n",
       "                               Company Experience  \\\n",
       "1                     Trigent Software    3-5 Yrs   \n",
       "2                     Trigent Software    3-5 Yrs   \n",
       "3           India Medtronic Pvt. Ltd,.    1-4 Yrs   \n",
       "4              Infobahn Softworld Inc.    5-8 Yrs   \n",
       "5        WEIWO Communication Pvt. Ltd.    4-8 Yrs   \n",
       "6   GCC SERVICES INDIA PRIVATE LIMITED    5-9 Yrs   \n",
       "7     Allegis Services India Pvt. Ltd.    2-5 Yrs   \n",
       "8     Allegis Services India Pvt. Ltd.    3-5 Yrs   \n",
       "9      Enzen Global Solutions Pvt. Ltd    6-8 Yrs   \n",
       "10                      Liventus, Inc.    5-8 Yrs   \n",
       "\n",
       "                                             Location  \n",
       "1                                 Bangalore/Bengaluru  \n",
       "2                                 Bangalore/Bengaluru  \n",
       "3   Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5                         Bangalore/Bengaluru(Ulsoor)  \n",
       "6                                 Bangalore/Bengaluru  \n",
       "7                                 Bangalore/Bengaluru  \n",
       "8                                 Bangalore/Bengaluru  \n",
       "9                                 Bangalore/Bengaluru  \n",
       "10            Bangalore/Bengaluru(2nd Phase JP Nagar)  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"de01b7b5640a8412edb1a5bb1e74181c\", element=\"b1a72e1d-2959-41e5-bfb1-f8ce5ae8dd00\")>"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "jobsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "location = driver.find_element_by_id('qsb-location-sugg')\n",
    "location.send_keys(\"Bangalore\")\n",
    "search = driver.find_element_by_class_name('btn')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "company = []\n",
    "locations = []\n",
    "desc_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "description_url = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "for u in description_url:\n",
    "    desc_url.append(u.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-senior-data-scientist-datamatics-global-services-ltd-bangalore-bengaluru-8-to-13-years-040821003517?src=jobsearchDesk&sid=1628220584883360&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-symbiosis-international-w-l-l-bangalore-bengaluru-10-to-15-years-050821004331?src=jobsearchDesk&sid=1628220584883360&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-mcafee-software-india-pvt-ltd-bangalore-bengaluru-4-to-8-years-050821501145?src=jobsearchDesk&sid=1628220584883360&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-engineers-data-scientist-and-sap-teamware-solutions-bangalore-bengaluru-7-to-10-years-300721500677?src=jobsearchDesk&sid=1628220584883360&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-python-data-scientist-mindtree-limited-bangalore-bengaluru-3-to-5-years-040821500207?src=jobsearchDesk&sid=1628220584883360&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-software-developer-data-scientist-nlp-machine-learning-dot-net-cunesoft-india-private-limited-bangalore-bengaluru-3-to-8-years-190121001281?src=jobsearchDesk&sid=1628220584883360&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-uber-bangalore-bengaluru-6-to-8-years-050821500683?src=jobsearchDesk&sid=1628220584883360&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-associate-data-scientist-novotree-minds-consulting-pvt-limited-bangalore-bengaluru-4-to-7-years-300721001832?src=jobsearchDesk&sid=1628220584883360&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-5-to-10-years-260721907182?src=jobsearchDesk&sid=1628220584883360&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-8-to-12-years-230721906918?src=jobsearchDesk&sid=1628220584883360&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-publicis-groupe-bangalore-bengaluru-2-to-5-years-030821501259?src=jobsearchDesk&sid=1628220584883360&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-bidgely-technologies-private-limited-bangalore-bengaluru-4-to-6-years-030821500043?src=jobsearchDesk&sid=1628220584883360&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-goals-101-data-solutions-pvt-ltd-new-delhi-bangalore-bengaluru-delhi-ncr-4-to-8-years-030821000870?src=jobsearchDesk&sid=1628220584883360&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-permanent-role-onward-technologies-limited-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-11-years-030821002780?src=jobsearchDesk&sid=1628220584883360&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-time-series-nlp-artificial-intelligence-societe-generale-global-solution-centre-pvt-ltd-bangalore-bengaluru-3-to-8-years-040821010040?src=jobsearchDesk&sid=1628220584883360&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-randstad-india-pvt-ltd-bangalore-bengaluru-4-to-9-years-280721000424?src=jobsearchDesk&sid=1628220584883360&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-red-hat-india-pvt-ltd-bangalore-bengaluru-8-to-13-years-220721008125?src=jobsearchDesk&sid=1628220584883360&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-tech-lead-data-science-confidential-bangalore-bengaluru-6-to-9-years-020821903704?src=jobsearchDesk&sid=1628220584883360&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-l-a-consultancy-kochi-cochin-hyderabad-secunderabad-pune-chennai-delhi-ncr-bangalore-bengaluru-5-to-9-years-310721903849?src=jobsearchDesk&sid=1628220584883360&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-tensorflow-machine-learning-getinz-techno-services-mumbai-hyderabad-secunderabad-chennai-bangalore-bengaluru-7-to-10-years-250721900474?src=jobsearchDesk&sid=1628220584883360&xp=20&px=1']"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in desc_url:\n",
    "    driver.get(d)\n",
    "    try:\n",
    "        content= driver.find_element_by_xpath(\"//div[@class='dang-inner-html']\").text.replace('\\n',\" \").replace('\\n\\n',\" \")\n",
    "        \n",
    "        desc.append(content)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Roles and Responsibilities  Details in lined for Hiring Team to focus: The hiring is for a single Data Scientist (7-8+yrs) as he/she shall be an individual contributor. We shall seek for a strong java/python/scala with expertise into frameworks ML (spark/keras/tensorflow). ML concepts has to be thorough with proven expertise in ( Decision Trees, Random Forest, NLP) Deep Learning is excluded. Desired Candidate Profile   Perks and Benefits',\n",
       " \"Required Candidate profile We are looking for a Senior Data Scientist with a min of 10 years experience in Banking Financial Domain (especially Compliance related) and a solid background in Cloudera. As a Cloudera Specialist, you must be adept in Cloudera tools like CDH, CEPH, CM, CMA, Data node EDH, HVE, JAS, NameNode, Nodemanager, QJM, QJN, RM and ZK. This will be a two years assignment to one of the Leading Class A banks in Abu Dhabi. Candidate should have finished two or three full implementations of Data Analytics in Compliance in large Enterprise Banks. Should be having thorough knowledge in R, Python, Scala on demand and Jupyter Notebooks. Should be having hands experience in CCA Spark and Hadoop developer. Should be having a Financial Compliance Background with a good knowledge and hands on expertise on Compliance related domains. Should be a Machine Learning expert and create new models and use various library in that area. You should have proven skills in this area. Should be having a thorough theoretical and practical idea on the following systems (From a Data Scientist Perspective) HDFS Yarn MapReduce Hive Pig Apache Ambari HBase / Apache Impala Storm Oozie Ranger Zookeeper Various data ingestion tools like Sqoop, flume, Kafka Various reporting tools like Drill, Phoenix, Zeppelin Will be an added advantage if you have exposure to GPU processing, Tensor Flow and Data Lakes. Should be able to produce high Quality Business documentation, Project Management, Agile Framework practices as needed. Should inspect the current Cloudera Architecture and suggest enhancements or improve it. Should be able to communicate with Senior Business Management ideas, concepts and deliverables. If you have certifications on Cloudera (Cloudera Data Engineer, Spark and Hadoop Developer), it will be an added advantage. Data Scientist - Compliance Responsibilities: Use advanced analytics methods to extract value from business data Perform large-scale experimentation and build data-driven models to answer business questions Conduct research on cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence Determine requirements that will be used to train and evolve deep learning models and algorithms Articulate a vision and roadmap for the exploitation of data as a valued corporate asset Influence product teams through presentation of data-based recommendations Evangelize best practices to analytics and products teams Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing analytics delivery, re-designing infrastructure for greater scalability, etc. Build analytics tools that utilize the data to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with analytics related technical issues and support their data infrastructure needs. Work with data and analytics experts to strive for greater functionality data systems Typical skills and background: SKILLS: Can work with data to identify patterns. Use judgement to form conclusions that may challenge conventional wisdom and focus on the crux of issues to identify high-leverage intervention points and strategies. Rapidly acquire new knowledge and learn new skills Seek to understand business needs and get results that have a clear, positive, and direct impact on business performance Apply different strategies to convince others to change their opinions or plans and ensure that proposals or arguments are supported by strong logic and a compelling business case, addressing all relevant factors. Consider the relative costs and benefits of potential actions to choose the most appropriate one Communication and storytelling Teamwork and collaboration Banking domain business knowledge Advanced analytics modelling and orchestration Solid development skills in Java, Scala and SQL Sound knowledge of using data science tools and languages like Cloudera Data Science Workbench (CDSW), Jupyter Notebook, Python etc. Clear hands-on mastery in big datab systems - Hadoop ecosystem, Cloud technologies (AWS, Azure, Google), in-memory database systems (HANA, Hazel cast, etc) and other database systems - traditional RDBMS (Terradata, SQL Server, Oracle), and NoSQL databases (Cassandra, MongoDB, DynamoDB) Comfortable in dashboard development (Tableau, Powerbi, Qlik, etc) and in developing data analytics models (R, Python, Spark) EXPERIENCE AND QUALIFICATION: Masters degree from top-tier college/university in Computer Science, Statistics, Economics, or other closely-related field Minimum of 6 years' hands-on experience with a strong data background Extensive experience working with Big Data tools and building data solutions for advanced analytics Experience with statistical software, scripting languages, and packages (e.g. R, MATLAB, SAS, and Python) Considerable experience in solving business problems with advanced analytical solutions Proven experience in conducting statistical analysis and building models with advanced scripting language such as R, SPSS, or other analytic tools. Experience building and deploying predictive models, web scraping, and scalable data pipelines. Strong understanding of statistical methods and skills such as Bayesian Networks Inference, linear and non-linear regression, hierarchical, mixed models/multi-level modeling Practical knowledge across data extraction and transformation tools - traditional ETL tools (Informatica, Altryx) as well as more recent big data tools Financial Renumeration will be based on your skills and expertise. Notice Period of 30 to 45 days preferred Previous working experience in Middle East and Gulf regions preferred Roles and Responsibilities   Desired Candidate Profile   Perks and Benefits\",\n",
       " 'Data Scientist Primary Location India, Bangalore Date posted 08/01/2021 Apply Now Save Job ID: JR0024575   Job Title: Data Scientist   Role Overview: Data scientist will be doing research on innovative projects in platform engineering group at McAfee. Platform Engineering Group is the is one of the core groups responsible for collecting data from millions of sensors from various products of Enterprises, using the data to protect the customers, provide insights and necessary actions to be taken for security gap.  This position is an integral part of the McAfee Enterprise business segment which was acquired by Symphony Technology Group (STG) in July 2021. McAfee Enterprise and its team members remain committed to keeping governments and enterprises safe. This position is dedicated to and part of the McAfee Enterprise business.    Company Overview McAfee is a leader in personal security for consumers. Focused on protecting people, not just devices, McAfee consumer solutions adapt to users needs in an always online world, empowering them to live securely through integrated, intuitive solutions that protects their families and communities with the right security at the right moment. About the Role: Develop Machine learning models to analyze and obtain practical insights from large volume of data that requires expertise at data exploration, analysis and feature engineering Experiment and Develop POCs of innovative ideas to come up with new solutions for addressing security gaps Create machine learning pipelines to automate generation of efficient and better models Communicate and work with engineering teams to productionize the solutions Taking ownership and responsibility of the solutions and driving to closure Participate in data and product analytics to develop customer insights and product features Implement newer machine learning algorithms and models to improve the efficacy of the existing solutions Publish research papers on the experiments and machine learning solutions About you : 5+ years of experience in the field of Data Science 5+ years of programming experience in at least one of Python or Java 3+ years of working experience on large datasets using ML and experience with ML model life cycle PhD degree in Computer Science, Data Science, Statistics, Mathematics or other related fields is preferred Deep knowledge in Natural Language processing, Deep learning, statistics, predictive modeling and time series analysis. Passionate about Cybersecurity and want to apply machine learning solutions in this space to solve security problems. Experience working on Big data problems Experience working on problems relevant to detecting risk, fraud and trust is an added advantage Experience in working in AWS cloud environment is an added advantage Experience with Publishing research papers',\n",
       " 'Dynamic recruiting professional with 7 - 10 years of high-performance tech recruiting experience with search firms and /or mid-large-sized technology companies. Experience in engaging and hiring the best talent for Data Engineers, Data Scientist and SAP Open to learning from your peers managers, anything that helps you do your job better day in day out also often share best practices in hiring talent attraction strategies with them. Work well with teams as also on your own as a high-impact individual contributor. Use social media, job boards, Internet sourcing, and other technical means to source candidates for open jobs. Understanding of modern recruiting methods like hackathons but are equally comfortable with old school methods as well. Work with internal technology teams and hiring managers to assist with recruitment efforts across levels. Work in sync with the company-wide recruitment strategy. This may include job posting optimization, recruiting marketing channel development, search selection using job boards, digital and non-digital employment marketing, comprehensive recruitment campaign planning, talent planning, stakeholder management, etc. Identify and source appropriate talent for current open roles within the organization using traditional non-traditional means of recruiting. Proactively develop talent pools/talent communities to dip into when hiring is in full swing. Manage the end-to-end recruitment process and life-cycle, including sourcing, initial assessments, telephonic personal interviews culminating in offers maintaining the appropriate MIS.',\n",
       " 'Basic Qualifications 3-5 years of hands-on experience in in data science, applied statistics, machine learning, data mining, statistical modeling tools and underlying algorithms 3-5 years of hands-on experience building production grade machine learning enabled solutions end to end. 3-5 years of experience in statistical modeling methods, time series, text mining, optimization, information retrieval 3-5 years hands-on experience using R, Python or and other languages appropriate for large scale analysis of numerical and textual data 3-5 years Hands-on experience using SQL and data mining Experience with experiments, machine learning, deep learning, anomaly detection, predictive analysis, exploratory data analysis, and other areas of data science Experience using large data systems Advanced data visualization experience Experience in business, program and/or strategy planning Experience in business, program and/or strategy planning Experience in business, program and/or strategy planning. Job Requirements: Python, SQL, R Language, Machine Learning for Rules, AI Hub, Machine Learning Fundamentals, Machine Learning Application',\n",
       " 'Dear Candidates We are looking for a competent and enthusiastic candidate with the below requirement. This vital role ensures Cunesoft India Pvt Ltd (a Phlexglobal Company) Bangalore can provide a high-quality end product to internal and external users. This position requires strong technical and communication skills as well as both independent and team working, including working closely with all other areas of the software delivery team and the rest of the Technology department. Roles and Responsibilities  Key Activities Develop and improve the existing data mining and NLP related processes within our Regulatory Data Management platform Develop new ways of improving and transforming the regulatory processes of Phlexglobal customers. Interact with product management, project management and development teams to develop additional modules and functions within the Phlexglobal Cloud Platform Design and create solutions for pre specified modules and functions Use existing tools and techniques to develop and test new and existing work Define, create and execute automated test cases, i.e. unit tests Participate in troubleshooting and triaging of issues with different teams to drive towards root cause identification and resolution Support production deployment of applications and perform validation testing during the off-hours maintenance windows Support and fix existing and new identified issues by either customers or internal test teams.  Desired Candidate Profile   Required Skills & Experience  Minimum 3+ years working experience in NLP, Artificial Intelligence, Machine Learning, Text Mining, Neural Networks Strong programming skills using PYTHON In depth experience with OpenNLP, Stanford NLP or related NLP / data mining technologies In depth experience with Python and data libraries such as scikit learn, pandas, numpy, etc. Selecting features, building and optimizing classifiers using Machine learning techniques Excellent understanding of Machine Learning Techniques and Algorithms. Must have Data mining / Natural Language Processing experience Must have very good understanding of GIT Processing, Cleansing, and verifying the integrity of data Develop custom data models and algorithms to apply to data sets. Defining validation strategies Defining the preprocessing or feature engineering to be done on a given dataset Defining data augmentation pipelines Training models and tuning their hyperparameters Analyzing the errors of the model and designing strategies to overcome them Deploying models to production  Added advantages 3+ years experience using Microsoft .NET / C# Exposure to ML.Net, AutoML, NimbusML, etc Good knowledge of Microsoft Visual Studio is preferred Good to have Microsoft SQL Server, preferably Microsoft SQL Azure Previous experience in the Life sciences area  Other requirements Excellent verbal and written communication skills Must be flexible, independent and self motivated Punctual, Regular and consistent attendance As part of the Interview process, you should have attempted the below mentioned Kaggle project.  https://www.kaggle.com/c/titanic  We would like to arrange a phone interview with you. Please confirm your interest in this position by sending your recent CV attached along with below details.  Total years of Experience :  Relevant Experience :  Current CTC :  Expected CTC :  Notice Period :  Current Location :  Best time to talk to you :  Candidates with relevant experience can contact me.  We are looking for a candidate who can join us immediately / in less than 15-20 days / 30 days / ASAP  Please ignore, if you have already been interviewed within 3 months.  Thanks Srini  sarumugam@phlexglobal.com +91 63660 85842  Dot Net Developer  Junior (3-5 yrs), Mid (5-8 yrs) & Lead (8-12 yrs) level roles.  Commercial experience in web development using the full Microsoft .Net development stack (specifically C#, MVC, .Net Core), SQL, front-end frameworks (jQuery, React, etc).  Coding, Entity framework, Linq, Source control system (Any - TFS or GIT), Data structures  Skilled in modern development principles (Agile, SOLID, TDD, design patterns, IoC)  At least theoretical knowledge - know-SQL database (example Azure Cosmos)  Good to have - Ideally experience of Azure, MVVM, microservices, message bus, containerisation, serverless.  Microsoft .Net development stack, C#, MVC, .Net Core, SQL, front-end frameworks, jQuery, React, Entity framework, Linq, TFS, GIT, Data structures, Agile, SOLID, TDD, design patterns, IoC, SQL database, Azure Cosmos, Azure, MVVM, microservices, message bus, containerisation, serverless',\n",
       " \"About the role We are looking for skilled motivated professionals who will support and own multiple projects globally that drive business growth while still balancing compliance risk and partner friction. The role will cover areas such as (not limited to) Sanctions screening; Partner and user compliance; Customer due diligence; Transaction monitoring; Metrics development and monitoring; and Model and Strategy development - to help balance partner friction and compliance risk What you'll do Develop and manage user risk rating models that meet applicable regulatory requirements and are aligned with standard methodologies and practices. Interpret large amounts of complex data to formulate problem statements, concise conclusions regarding underlying risk dynamics, trends, and opportunities Identify key risk indicators and metrics while developing and monitoring key parameters, enhance reporting, and identify new areas of analytic focus to better understand operational risk. Own compliance specific area - end to end - ranging from the discovery of the business problem to eventually working with the Engineering/Product teams to execute it Strategy design and analysis of domain-specific use-cases such as Reduction of cost of compliance; Improve monitoring mechanism to alert any anomaly in compliance or business metric; Improve funnel for Partner onboarding, thereby improving user experience; and Drive multiple experiments to evaluate and quantify the hypothesis Extensive data analytics and SQL query writing Predictive modeling / Machine learning algorithms - using random Forest / Decision tree / Logistic regression Key Qualifications 6 years of proven experience in a data-focused role such as product analytics, business analytics, business operations, or data science Education in Engineering, Computer Science, Math, Economics, Statistics or equivalent experience Past experience in Payments or Compliance with a Product / Tech company serving millions of customers on multiple platforms and countries BA/BS in Mathematics, Statistics, Computer Science, Economics, Business or analytical field SQL mastery. Write efficient and complex code in SQL Experience in Python/R and in experimentation, A/B testing, and statistical modeling Define business metrics, including Key Performance Indicators, for financial products, in close partnership with Product Management and other leaders Proven ability to handle large datasets, explore and utilize raw data feeds Excellent data visualization skills Love of data - you just go get the data you need and turn it into an insightful story. You know how to convert data into decisions without getting stuck in paralysis by analysis A well-organized, structured approach to problem-solving Strong sense of ownership, accountability, and entrepreneurial spirit Able to lead change and solution-oriented Great communicator, problem-solver confident in decision making Independent autonomous, while still a strong teammate Enthusiastic, self-starting and thrives in changing, agile environment.\",\n",
       " 'Roles and Responsibilities As a Senior Associate you will be responsible for the overall health of a client engagement. You will be challenged with a mix of technical as well as business strategy/planning problems. As a key member of the team, you will be expected to drive adoption of new technologies, tools and process improvements within the team to build world class analytical capabilities for customers.  Primary Responsibilities:  Ability to work with business users to refine analytical requirements and breakdown/solve complex business problems Staying connected with analytics industry trends in data, techniques, technologies and leveraging them to develop learning packages as well as evangelizing their use across teams Depending on the client engagement, leading a team of analysts/associates and mentoring people in a fast paced, learning driven environment Strong application knowledge of tools (R/SAS/Python/SPSS etc.) Hands on experience in statistical techniques (Regression, Machine Learning, Classification, Time series, etc.) Experience of working on analytics projects and initiatives with 5+ years of experience  Additional Responsibilities: Proficiency with Git Understanding of software development methodologies (Agile essential), values, and procedures Experience or certifications with visualization tools (Tableau/Qlik/PowerBI etc.) Well versed with big data handling using Hadoop, etc. Project management certifications: PMP/ CAPM/ CSM  Desired Candidate Profile   Perks and Benefits',\n",
       " 'Work location: Bengaluru (Currently, Remote) Shift timing: 12PM to 9PM Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. Develop a use case roadmap for a problem area or capability for the business. Frame the business problem into a Data Science or modelling problem. Extract data from multiple sources. Mine and analyze data from company databases to drive optimization and improvement of product. Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with Client Support, Product Management and Engineering team to strategize and execute the development of data products. Processing, cleansing, and verifying the integrity of data used for analysis. Undertake preprocessing of structured and unstructured data. Data mining using state-of-the-art methods. Selecting features, building and optimizing classifiers using ML/AI techniques. Present technical solutions to internal and external stakeholders in a formal setting, effectively communicating key concepts and functionalities Effectively manage client expectations via direct and frequent communication with high quality results Develop front end deliverable solutions for stakeholders utilizing BI tools such as Tableau, Cognos, Excel, or similar Work on multiple assignments concurrently, while handling priorities and challenges and meeting timelines basis project plan and roadmap. Build self-service tools for error detection, diagnosis, and predictive metrics. Build project plans, maintain to-do list, organize work, follow coding ethics, and have an eye for detail   Qualifications Bachelor s or Master s degree in a quantitative discipline (e.g., data science, statistics, economics, mathematics, computer science) or significant relevant coursework/experience 4+ years professional experience in the field of data science or business intelligence Demonstrated proficiency in PYTHON/SCALA/SQL and BIG DATA technologies and the proven ability to program in big data/cloud technologies such as AWS SPARK; minimum 3 years of experience Experienced with Machine Learning algorithms such as logistic regression, linear regression, lasso regression, k-means, random forest, XG boost, KNN, SVM and neural network; minimum 2 years of experience Able to produce elaborate documents/narrative suggesting actionable insights and recommendations leveraging BI tools such as Tableau Expertise with Microsoft Office products; including Excel, PowerPoint, Word Great communication skills. Excellent written and verbal communication skills for coordinating across teams. Self-driven and results oriented. Willing to stretch to meet tight timelines. Strong team player with ability to collaborate effectively across geographies/ time zones Good understanding of Digital Marketing, Campaign Measurement, Web Analytics Desirable Qualifications: Professional experience working with R Professional experience working with Power BI, Cognos, Dash, Looker, Domo Professional experience in fraud analytics, customer journey, attribution modeling, churn modeling, predictive analytics, customer segmentation, feature creation, statistical testing, a/b testing, production curve modeling, NLP, and partner recommendations. Professional analytical consulting experience with clients in Retail, Finance, Travel, or Home and Business Services',\n",
       " 'Bidgely is looking for extraordinary and dynamic Data Scientists to be part of its core team in Bangalore. You must have delivered advanced statistical and machine learning models as part of commercial products and created substantial intellectual property with business impact. You must enjoy working with large data and finding interesting patterns in the data through analytics experiments in a methodical and data driven scientific way. Be part of a highly energetic and innovative team that believes nothing is impossible with some creativity and hard work. Responsibilities Research and develop advanced statistical and machine learning models for analysis of large-scale, high-dimensional data. Dig deeper into data, understand characteristics of data, evaluate alternate models and validate hypothesis through theoretical and empirical approaches. Productize proven or working models into production quality code. Collaborate with product management, marketing and engineering teams in Business Units to elicit understand their requirements challenges and develop potential solutions Stay current with latest research and technology ideas; share knowledge by clearly articulating results and ideas to key decision makers. File patents for innovative solutions that add to company s IP portfolio Requirements 4 to 6 years of strong experience in data mining, machine learning and statistical analysis. BS/MS/PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes (only IITs / IISc / BITS / Top NITs or top US university should apply) Experience in productizing models to code in a fast-paced start-up environment. Expertise in Python programming language and fluency in analytical tools such as Matlab, R, Weka etc. Strong intuition for data and Keen aptitude on large scale data analysis Strong communication and collaboration skills.',\n",
       " 'Roles and Responsibilities:  Work as part of a product team in defining, prototyping and implementing data science models/algorithms as part of the product. Be able to research and apply the latest Machine Learning architecture solutions that work for big data Batches and Streams. Build data expertise, act like an owner for the company and manage complex data systems for a product or a group of products. Designing, integrating and documenting technical components for data flows or applications that perform analysis at a massive scale. Along with project managers, own the business outcomes/metrics which the data science model/algorithm drives. Build large scale data systems that would work across multiple geographies Solid understanding of the mathematics of ML - Probability, Statistics, Linear Algebra of Matrices, Modelling Hyperparameter tuning for speed of learning & model performance. Ability to understand business concerns and formulate them as technical problems that can be solved using Data/Math/Stats/ML. Experience working as part of a product team, along with engineers and product managers, to define the problem and execute the data science solution.   Desired Candidate Profile:  4+ Years of Relevant Experience. Hands on experience of coding in Python and SQL (MySQL and Postgres) Hands-on experience of applying and tuning the following algos of data science in multiple verticles: Recommendation Algos (Collaborative filtering, Content filtering (ALS etc.)) Classification and Regression Algos Machine Learning Algos (XGBoost, Random Forest) Clustering Algos (KMeans) Dimensionality Reduction Algos (PCA) Experience of coding in Pyspark and Scala Working knowledge of Airflow, Hadoop (HDFS) and Git Tuning of various performance matrix (for accuracy, precision, recall, F1 Score, AUC, ROC) Experience in Deep Learning Algos (Neural Network)',\n",
       " 'Greetings from Onward Technologies!  We are Hiring for Data scientist for one of our prestigious Client. Permanent Role. Job description: Exp : 6 to 11years Location : Bangalore Np : Max 15 to 30days  Primary Skill: Data science, Machine Learning,Structured Data Analysis',\n",
       " 'Roles and Responsibilities Job Description What You Will Do :Job Description: Senior Data Scientist Our Analytics Services group has an open, full-time position in the Bangalore region for a Senior data scientist.  The senior data scientist will be working with our clients on new product development/ new solution development as well as improve on current solutions. Functional Responsibilities         Develop strong statistical approaches to solution development. Candidate should be well versed in executing statistical models  on Regression, Ancova, Factor analysis, Cluster analysis, Text based mining, and similar modeling approaches.         Evaluate model effectiveness and ability to translate the statistical requirements into excel based examples. Candidate should be proficient in writing good code in Python, PySpark.         Strong proficiency with manipulating big data with R , Python, SQL. A high comfort level with data manipulation and extraction of meaningful insights from large data and prior experience of working with large data is a plus. Experience with SAS is acceptable Candidate should have good working knowledge on AI and ML and should have applied these techniques on some of their recent projects         Being creative in identifying new techniques and processes to streamline and increase efficiency and effectiveness of current work-streams is a plus.         High level of attention to detail and problem solving  Professional requirement Post graduate degree in Economics, MBA, Statistics, Mathematics, Operations Research, Quantitative Analysis, or related field 6-10 years of consolidated work experience in Analytic Industry. Strong statistical and quantitative analysis skills. Knowledge of Statistical Analysis techniques which are used in Marketing analytics. Advanced knowledge of SQL and experience with statistical packages such as Python, Spark, PySpark, R. Experience with Oracles Exadata environment is a plus. Excellent data interpretation skills. Experience in using charting/reporting Skilled in MS-Office, specifically Excel and Powerpoint Should have basic knowledge of market research & any specific knowledge on Retail and FMCG/CPG/Pharma industry will be an added advantage. Knowledge on Retailer loyalty card data/Store transaction level data will be an added advantage.   Desired Candidate Profile Must have skill: statistical modeling, pyspark, python NP : we can accept max 60 days. 90 days NP please avoid',\n",
       " \"Job Summary  The Red Hat Engineering team is looking for a Senior Data Scientist to join us in Bangalore, India. In this role, you will design, develop, and program methods, processes, and systems to consolidate and analyse unstructured, diverse big data sources to generate actionable insights and solutions for customer services and solutions enhancement. You'll interact with product and service teams to identify questions and issues for data analysis and experiments. You'll develop and code software programs, algorithms, and automated processes to cleanse, integrate, and evaluate large data sets from multiple disparate sources. As a Senior Data Scientist, you will identify meaningful insights from large data and metadata sources and communicate them to product, service, and business managers.  Primary Responsibilities  Data mining, and statistical techniques and algorithms to create new scalable solutions for business problems by analysis of large amounts of data Ability to understand a business problem and translate it to data science requirements and develop solutions. Develop solutions using NLP, work on solutions using advanced NLP algorithms like BERT, GRU etc Develop analytical tools and data offerings Create tools that you yourself would like to and could use Institutionalise best practices for ML solution development life cycle, including model building, model deployment, develop data pipeline, cloud deployment and model re-training Participate in the community blog, participate in forums, and speak at user groups and conferences Required Skillset  5-8 years of experience in machine learning (ML) model development Experience in Cloud infra domain Experience in defining dataset requirements for a business problem Experience developing in Python Experienced in deploying ML models in cloud-based architecture Experience in developing data pipelines from disparate data sources for ML solutions. Experience with REST Services, Service-Oriented Systems and Micro-services architecture Experience with Docker, Kubernetes and Cloud Technologies Experience in define, design and develop prototypes or proofs of concepts Experience with agile framework and mode of working\",\n",
       " 'Role : Sr Data Scientist / Tech Lead - Data Science  Responsibilities - Lead a team of data scientists, machine learning engineers and big data specialists Be the main point of contact for the customers Lead data mining and collection procedures Ensure data quality and integrity Interpret and analyze data problems Conceive, plan and prioritize data projects Build analytic systems and predictive models Test performance of data-driven products Visualize data and create reports Experiment with new models and techniques Align data projects with organizational goals  Requirements (please read carefully) Very strong in statistics fundamentals. Not all data is Big Data. The candidate should be able to derive statistical insights from very few data points if required, using traditional statistical methods. Education - no bar, but preferably from a Statistics academic background (eg MSc-Stats, MSc-Econometrics etc), given the first point. Any Relevant Graduate (BE/B Tech, MCA Prefer) Strong expertise in Python (any other statistical languages/tools like R, SAS, SPSS etc are just optional, but Python is absolutely essential). If the person is very strong in Python, but has almost nil knowledge in the other statistical tools, he/she will still be considered a good candidate for this role. Proven experience as a Data Scientist or similar role, for about 7-8 years Solid understanding of machine learning and AI concepts, especially wrt choice of apt candidate algorithms for a use case, and model evaluation. Good expertise in writing SQL queries (should not be dependent upon anyone else for pulling in data, joining them, data wrangling etc) Knowledge of data management and visualization techniques -- more from a Data Science perspective. Should be able to grasp business problems, ask the right questions to better understand the problem breadthwise /depthwise, design apt solutions, and explain that to the business stakeholders.  Work Experience Required: 6-9 yrs.',\n",
       " 'Key Requirements: • Data-oriented personality • Good applied statistics skills, such as distributions, statistical testing, regression, etc. Experience with Deep Learning, BERT, Transformer, LSTM, RNN, Text Classification, Clustering. • At least 2 - 9 years of experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.  • Experience working with and creating data architectures, data management, data analysis and data extraction  • Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.  • Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.  • Ability to grasp nuances of business quickly.  • Ability to problem solve and break down the complex problem into solvable pieces.  • Ability to deliver quick and accurate results for each analysis/task  • Ability to do work within tight timelines  The ideal candidate should constantly stays on top of the industry’s trends, in order to provide forward-thinking recommendations to the business. In this capacity, the candidate will strive to build an in-depth understanding of the problem domain and available business data assets, especially those pertaining to strategic initiatives and value-based programs.  The idea candidate would identify the data the business should be collecting, devises methods of instrumenting the business’s system in order to extract this information and work with other data and analytics departments to develop the processes that transform raw data into actionable business insights and will also mentor supporting personnel for this position, continuously ensuring effective execution of duties at this junior level.',\n",
       " 'Hiring for B2B saas product companies across Pan INDIA  Skills And Experience :  - Masters in a Computer Science, Artificial Intelligence, Machine Learning, or related technical field) or Ph.D. preferred  - 7+ years of experience in data science roles  - Experience in applied machine learning or artificial intelligence  - Experience with predictive modeling (classification, regression, parameter tuning, optimization criteria, feature selection), preferably with multiple techniques is a requirement.  - Experience applying modern machine learning techniques  - Experience with one or more general-purpose programming languages (Python, Java, or C/C++)  - Experience advising a team on innovative methodologies, data science tools, and environments on machine learning and data modeling applications.  Requirements:  - Frameworks - TensorFlow, PyTorch, etc  - Cloud platforms and Big Data domains is a plus (e.g. Hadoop, Spark, AWS, GCP, MS Azure)  - working with Geospatial data is a plus']"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc2 = []\n",
    "for d in desc_url:\n",
    "    driver.get(d)\n",
    "    try:\n",
    "        content= driver.find_element_by_xpath(\"//div[@class='clearboth description']\").text.replace('\\n',\" \").replace('\\n\\n',\" \")\n",
    "        \n",
    "        desc2.append(content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We are looking for an experienced Data Scientist to join a growing team. In this role you will apply your knowledge of mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced analytic solutions to identify cybercrimes and hacktivism threats in a scalable way. There is no limitation on the analytics and could be as simple as rule-based detection or as complex as using AI/ML to classify threats. You ll also evaluate accuracy and quality of data sources, as well as the designed models. In addition, you ll evaluate new and existing data sources, processes, and architecture to develop recommendations.\\nWhat you ll do:\\nAs a Senior Data Scientist you will:\\n- Design the overall architecture and functions of a security application\\n- Develop & Implement the plan\\n- Manage the code base and provide incremental updates / fixes\\n- Ensure the code is solving the problem statement / use cases\\n- Document and present your solution and ideas to stakeholders\\nRequired Technical and Professional Expertise\\nMin 5 years of Experience in data analytics, predictive analytics, mathematics, statistics, or similar field.\\nExperience in end-to-end ML engineering / MLOps.\\nExperience in R, Python, Spark, TensorFlow, PyTorch, Keras or similar\\nAdvanced knowledge of statistical concepts such as regressions, time series, mixed model, Bayesian methods, clustering, etc., to analyze data and provide insights.\\nUnderstanding of solutions on multiple public and private clouds.\\nUnderstanding of data usage, process analysis and improvement, technology development/support.\\nExperience in open source Machine, and Deep Learning frameworks, model validation and deployment tools, data pipeline technologies, and visualization and data storytelling tools.\\nExperience in data preparation, manipulation, and cleansing, in particular for large datasets.\\nExperience in manual and automated testing for machine learning applications.\\nExperience using RESTful APIs.\\nPreferred Technical and Professional Expertise\\nExperience in Information Security with a particular focus on Security Analytics, Security Architecture, and other cyber security.\\nDemonstrated experience in understanding unclear customer requirements and how they translate into technical tasks.\\nExcellent oral and written communication skills, especially in conveying complex technical topics to non-technical personnel.\\nGood knowledge of the Mitre ATT@CK framework or similar.\\nGood knowledge of frameworks and standards such as STIX, TAXII, NIST.',\n",
       " 'As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.\\n\\nYour Role and Responsibilities\\nData Science Consultants are adept across data science techniques using open source tools to solve varied use cases for our clients\\nThey work to build strong, enduring relationships with client staff based on innovation, trust and service excellence.\\nThey are accountable for successful delivery of complex data science engagements adhering to client s requirements and timelines\\nThey learn constantly and lead adoption of emerging technologies and approaches in their processes benefiting the client & IBM overall.\\nRequired Technical and Professional Expertise\\nBTech (with 8 years of relevant experience) or Masters (with 6 years of relevant experience) in Operations Research, Applied Mathematics/ Statistics/ Econometrics, Electrical or Systems Engineering, Physics or similar highly quantitative field\\nStrong ability to transform business requirements into data science formulations and implement the solutions in an efficient and scalable fashion\\nSound understanding of data science concepts, model development & performance tuning processes as well as coding, version control and CI/CD best practices\\nDemonstrated extensive experience in building and deploying production quality models in a live digital environment using data pipelines and ML Ops frameworks including handling model drift, retraining and version control lifecycle\\nHighly skilled in Python and various data science related libraries of Python including TensorFlow, Keras, Sci-Kit Lean, Pandas, Numpy and PySpark\\nExperience in Convolutional Neural Network / Computer Vision projects using TensorFlow, PyTorch and leveraging public / open-source libraries (VGG16, ImageNet, YOLO, OpenCV, etc) as well as ability to tweak, modify these CNN architectures when required for a specific business problem.\\nDemonstrated ability of scoping, executing and scaling multiple data science deliverables on their own\\nMust have worked in developing and deploying models using more than one cloud platform (AWS, Azure, GCP, IBM)\\nAbility to handle multiple projects as an individual contributor and as a lead / mentor to other team members managed directly or indirectly on a project / assignment\\nExcellent interpersonal and stakeholder management skills including ability to interact and present to senior stakeholders']"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc2 #last 2 descriptions are in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [] #combining values of desc1 and desc2 into main 'descriptions' list\n",
    "for i in range(0,8):\n",
    "    descriptions.append(desc[i])\n",
    "for j in range(0,2):\n",
    "    descriptions.append(desc2[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in JobDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Location\":locations[0:10],\"Job Description\":descriptions[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Datamatics Global Services Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilities  Details in lined f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>SYMBIOSIS International W.L.L</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Required Candidate profile We are looking for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>McAfee Software (India) Pvt. Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Scientist Primary Location India, Bangalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineers , Data Scientist and SAP</td>\n",
       "      <td>Teamware Solutions</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dynamic recruiting professional with 7 - 10 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python - Data Scientist</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Basic Qualifications 3-5 years of hands-on exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Developer - Data Scientist / NLP / Ma...</td>\n",
       "      <td>Cunesoft India Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dear Candidates We are looking for a competent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>About the role We are looking for skilled moti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Associate - Data Scientist</td>\n",
       "      <td>Novotree Minds Consulting Pvt Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilities As a Senior Associa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>We are looking for an experienced Data Scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As a Data Scientist at IBM, you will help tran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1                               Senior Data Scientist   \n",
       "2                               Senior Data Scientist   \n",
       "3                                      DATA SCIENTIST   \n",
       "4             Data Engineers , Data Scientist and SAP   \n",
       "5                             Python - Data Scientist   \n",
       "6   Software Developer - Data Scientist / NLP / Ma...   \n",
       "7                                      Data scientist   \n",
       "8                   Senior Associate - Data Scientist   \n",
       "9                               Senior Data Scientist   \n",
       "10                                  Sr Data Scientist   \n",
       "\n",
       "                                  Company             Location  \\\n",
       "1          Datamatics Global Services Ltd  Bangalore/Bengaluru   \n",
       "2           SYMBIOSIS International W.L.L  Bangalore/Bengaluru   \n",
       "3        McAfee Software (India) Pvt. Ltd  Bangalore/Bengaluru   \n",
       "4                      Teamware Solutions  Bangalore/Bengaluru   \n",
       "5                        Mindtree Limited  Bangalore/Bengaluru   \n",
       "6          Cunesoft India Private Limited  Bangalore/Bengaluru   \n",
       "7                                    Uber  Bangalore/Bengaluru   \n",
       "8   Novotree Minds Consulting Pvt Limited  Bangalore/Bengaluru   \n",
       "9                  IBM India Pvt. Limited  Bangalore/Bengaluru   \n",
       "10                 IBM India Pvt. Limited  Bangalore/Bengaluru   \n",
       "\n",
       "                                      Job Description  \n",
       "1   Roles and Responsibilities  Details in lined f...  \n",
       "2   Required Candidate profile We are looking for ...  \n",
       "3   Data Scientist Primary Location India, Bangalo...  \n",
       "4   Dynamic recruiting professional with 7 - 10 ye...  \n",
       "5   Basic Qualifications 3-5 years of hands-on exp...  \n",
       "6   Dear Candidates We are looking for a competent...  \n",
       "7   About the role We are looking for skilled moti...  \n",
       "8   Roles and Responsibilities As a Senior Associa...  \n",
       "9   We are looking for an experienced Data Scienti...  \n",
       "10  As a Data Scientist at IBM, you will help tran...  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  You have to use the location and salary filter.\n",
    "####  You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "####  You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "####  The location filter to be used is “Delhi/NCR”\n",
    "####  The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)\n",
    "\n",
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "jobsearch\n",
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "search = driver.find_element_by_class_name('btn')\n",
    "search.click()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[1]/div[2]/div[3]\")\n",
    "location_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "company = []\n",
    "locations = []\n",
    "xp = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "xp_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "for x in xp_tag:\n",
    "    xp.append(x.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in JobDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Experience\":xp[0:10],\"Location\":locations[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist / Sr. Data Scientist</td>\n",
       "      <td>WEGARNER SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Noida, Pune, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist - Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Immediate Openings For DATA Scientist with 6 T...</td>\n",
       "      <td>Entune IT Consulting Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Decimal Technologies Pvt Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>inVentiv International Pharma Services Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1                 Data Scientist / Sr. Data Scientist   \n",
       "2   Only Fresher / Data Scientist / Data Analyst /...   \n",
       "3                                      Data Scientist   \n",
       "4                       Senior Data Scientist - Noida   \n",
       "5                       Data Scientist / Data Analyst   \n",
       "6   Immediate Openings For DATA Scientist with 6 T...   \n",
       "7                                      Data Scientist   \n",
       "8                               Senior Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10              Data Scientist - Machine Learning/NLP   \n",
       "\n",
       "                                             Company Experience  \\\n",
       "1                 WEGARNER SOLUTIONS PRIVATE LIMITED    0-5 Yrs   \n",
       "2                          GABA Consultancy services    0-0 Yrs   \n",
       "3                            CBRE South Asia Pvt Ltd    2-4 Yrs   \n",
       "4     Optum Global Solutions (India) Private Limited    2-6 Yrs   \n",
       "5                                             CARS24    1-5 Yrs   \n",
       "6               Entune IT Consulting Private Limited    5-8 Yrs   \n",
       "7                      Decimal Technologies Pvt Ltd.    1-3 Yrs   \n",
       "8   inVentiv International Pharma Services Pvt. Ltd.    3-6 Yrs   \n",
       "9                       R Systems International Ltd.   5-10 Yrs   \n",
       "10                                            TalPro    2-6 Yrs   \n",
       "\n",
       "                                             Location  \n",
       "1                     Noida, Pune, Mumbai (All Areas)  \n",
       "2                Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "3                                    Gurgaon/Gurugram  \n",
       "4                                               Noida  \n",
       "5                                    Gurgaon/Gurugram  \n",
       "6   Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "7                                    Gurgaon/Gurugram  \n",
       "8   Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...  \n",
       "9                              Noida(Sector-59 Noida)  \n",
       "10                                   Gurgaon/Gurugram  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/index.htm' \n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobsearch = driver.find_element_by_id('sc.keyword')\n",
    "jobsearch\n",
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "location = driver.find_element_by_id('sc.location')\n",
    "location.send_keys(\"Noida\")\n",
    "search = driver.find_element_by_xpath('/html/body/header/nav[1]/div/div/div/div[4]/div[2]/form/div/button/span')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = []\n",
    "job_title = []\n",
    "ago = []\n",
    "Rating = []\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\")\n",
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='jobLink css-1rd3saf eigr9kq2']\")\n",
    "daysago_tag = driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "Rating_tag = driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column css-x75kgh e1rrn5ka3']//span\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in company_tag:\n",
    "    company.append(i.text)\n",
    "for j in title_tag :\n",
    "    job_title.append(j.text)\n",
    "\n",
    "for d in daysago_tag:\n",
    "    ago.append(d.text)\n",
    "for r in Rating_tag:\n",
    "    Rating.append(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '4.1',\n",
       " '',\n",
       " '4.6',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '3.3',\n",
       " '',\n",
       " '3.8',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '5.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '4.1',\n",
       " '',\n",
       " '3.1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '3.7',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '3.8',\n",
       " '',\n",
       " '',\n",
       " '3.8',\n",
       " '',\n",
       " '3.7',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '4.1',\n",
       " '',\n",
       " '3.8',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '4.3',\n",
       " '',\n",
       " '4.5',\n",
       " '',\n",
       " '3.8',\n",
       " '',\n",
       " '4.2',\n",
       " '',\n",
       " '3.8',\n",
       " '',\n",
       " '',\n",
       " '3.0',\n",
       " '',\n",
       " '3.9']"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating2 = []\n",
    "Rating2 = [Rating[x] for x in range(1,15,2)]\n",
    "for x in range(16,21,2):\n",
    "    Rating2.append(Rating[x] )\n",
    "Rating2\n",
    "Rating2 = [\"N/A\" if i =='' else i for i in Rating2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N/A', 'N/A', '4.1', '4.6', 'N/A', '3.3', '3.8', 'N/A', '5.0', 'N/A']"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in JobDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Job Age\":ago[0:10],\"Rating\":Rating2[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Age</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>10d</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Pixel Vision</td>\n",
       "      <td>21d</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Internship</td>\n",
       "      <td>DataTrained</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>22d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Crowe</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>24h</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Job Title                               Company Job Age  \\\n",
       "1   Associate Data Scientist  Liberin Technologies Private Limited     10d   \n",
       "2      Data Scientist Intern                          Pixel Vision     21d   \n",
       "3             Data Scientist                        Biz2Credit Inc    30d+   \n",
       "4    Data Science Internship                           DataTrained     24h   \n",
       "5      Data Scientist Intern          Salasar New Age Technologies    30d+   \n",
       "6             Data Scientist                       Newgen Software     22d   \n",
       "7             Data Scientist                                 Crowe    30d+   \n",
       "8             Data Scientist          Salasar New Age Technologies    30d+   \n",
       "9             Data Scientist                              Techlive    30d+   \n",
       "10       Data Science Intern                Data Trained Education     24h   \n",
       "\n",
       "   Rating  \n",
       "1     N/A  \n",
       "2     N/A  \n",
       "3     4.1  \n",
       "4     4.6  \n",
       "5     N/A  \n",
       "6     3.3  \n",
       "7     3.8  \n",
       "8     N/A  \n",
       "9     5.0  \n",
       "10    N/A  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/Salaries/index.htm' \n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobsearch = driver.find_element_by_id('KeywordSearch')\n",
    "jobsearch\n",
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "location = driver.find_element_by_id('LocationSearch')\n",
    "location.send_keys(\"Noida\")\n",
    "search = driver.find_element_by_xpath('/html/body/div[3]/div/div[1]/div[1]/div/div/form/button')\n",
    "search.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "company = []\n",
    "job_title = []\n",
    "Rating = []\n",
    "sals = []\n",
    "avg_sal = []\n",
    "sal_num = []\n",
    "Rating_tag = driver.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "title_tag = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg px-xsm']//span\")\n",
    "sal_num_tag = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']//span\")\n",
    "sals_tag = driver.find_elements_by_xpath(\"//div[@class='d-none d-lg-block']//p\")\n",
    "avg_sal_tag = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "for i in company_tag:\n",
    "    company.append(i.text)\n",
    "for j in title_tag :\n",
    "    job_title.append(j.text)\n",
    "for r in Rating_tag:\n",
    "    Rating.append(r.text)\n",
    "for n in sal_num_tag:\n",
    "    sal_num.append(n.text)\n",
    "for m in sals_tag:\n",
    "    sals.append(m.text)\n",
    "for a in avg_sal_tag:\n",
    "    avg_sal.append(a.text.replace(\"\\n \",\"\"))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹6,12,205/yr',\n",
       " '₹9,00,000/yr',\n",
       " '₹11,63,336/yr',\n",
       " '₹12,18,244/yr',\n",
       " '₹7,39,238/yr',\n",
       " '₹12,80,000/yr',\n",
       " '₹8,63,750/yr',\n",
       " '₹11,10,000/yr',\n",
       " '₹14,23,677/yr',\n",
       " '₹13,28,697/yr',\n",
       " '₹11,42,356/yr',\n",
       " '₹12,09,040/yr',\n",
       " '₹14,15,338/yr',\n",
       " '₹10,22,074/yr',\n",
       " '₹10,09,021/yr',\n",
       " '₹10,00,000/yr',\n",
       " '₹10,55,478/yr',\n",
       " '₹34,157/mo',\n",
       " '₹10,54,402/yr',\n",
       " '₹80,000/mo']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹3L',\n",
       " '₹13L',\n",
       " '₹6L',\n",
       " '₹27L',\n",
       " '₹6L',\n",
       " '₹22L',\n",
       " '₹5L',\n",
       " '₹1Cr',\n",
       " '₹4L',\n",
       " '₹16L',\n",
       " '₹8L',\n",
       " '₹15L',\n",
       " '₹5L',\n",
       " '₹15L',\n",
       " '₹6L',\n",
       " '₹15L',\n",
       " '₹8L',\n",
       " '₹20L',\n",
       " '₹4L',\n",
       " '₹22L',\n",
       " '₹2L',\n",
       " '₹18L',\n",
       " '₹6L',\n",
       " '₹17L',\n",
       " '₹10L',\n",
       " '₹21L',\n",
       " '₹4L',\n",
       " '₹16L',\n",
       " '₹8L',\n",
       " '₹13L',\n",
       " '₹9L',\n",
       " '₹15L',\n",
       " '₹8L',\n",
       " '₹20L',\n",
       " '₹12T',\n",
       " '₹63T',\n",
       " '₹4L',\n",
       " '₹17L',\n",
       " '₹25T',\n",
       " '₹1L']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating min and max salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sal =[]\n",
    "max_sal = []\n",
    "\n",
    "for i in range(0,len(sals),2):\n",
    "    min_sal.append(sals[i])\n",
    "for j in range(1,len(sals),2):\n",
    "    max_sal.append(sals[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹3L',\n",
       " '₹6L',\n",
       " '₹6L',\n",
       " '₹5L',\n",
       " '₹4L',\n",
       " '₹8L',\n",
       " '₹5L',\n",
       " '₹6L',\n",
       " '₹8L',\n",
       " '₹4L',\n",
       " '₹2L',\n",
       " '₹6L',\n",
       " '₹10L',\n",
       " '₹4L',\n",
       " '₹8L',\n",
       " '₹9L',\n",
       " '₹8L',\n",
       " '₹12T',\n",
       " '₹4L',\n",
       " '₹25T']"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹13L',\n",
       " '₹27L',\n",
       " '₹22L',\n",
       " '₹1Cr',\n",
       " '₹16L',\n",
       " '₹15L',\n",
       " '₹15L',\n",
       " '₹15L',\n",
       " '₹20L',\n",
       " '₹22L',\n",
       " '₹18L',\n",
       " '₹17L',\n",
       " '₹21L',\n",
       " '₹16L',\n",
       " '₹13L',\n",
       " '₹15L',\n",
       " '₹20L',\n",
       " '₹63T',\n",
       " '₹17L',\n",
       " '₹1L']"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in JobDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Minimum Salary(₹)</th>\n",
       "      <th>Maximum Salary(₹)</th>\n",
       "      <th>Average Salary(₹)</th>\n",
       "      <th>Number of Salaries</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹3L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹6,12,205/yr</td>\n",
       "      <td>18 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹27L</td>\n",
       "      <td>₹9,00,000/yr</td>\n",
       "      <td>18 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹11,63,336/yr</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>₹12,18,244/yr</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹7,39,238/yr</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹12,80,000/yr</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹8,63,750/yr</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹11,10,000/yr</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>₹14,23,677/yr</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹13,28,697/yr</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Job Title                    Company Minimum Salary(₹)  \\\n",
       "1   Data Scientist  Tata Consultancy Services               ₹3L   \n",
       "2   Data Scientist                        IBM               ₹6L   \n",
       "3   Data Scientist                  Accenture               ₹6L   \n",
       "4   Data Scientist                  Delhivery               ₹5L   \n",
       "5   Data Scientist         Ericsson-Worldwide               ₹4L   \n",
       "6   Data Scientist         UnitedHealth Group               ₹8L   \n",
       "7   Data Scientist         Valiance Solutions               ₹5L   \n",
       "8   Data Scientist                EXL Service               ₹6L   \n",
       "9   Data Scientist                      Optum               ₹8L   \n",
       "10  Data Scientist     Optum Global Solutions               ₹4L   \n",
       "\n",
       "   Maximum Salary(₹) Average Salary(₹) Number of Salaries Rating  \n",
       "1               ₹13L      ₹6,12,205/yr        18 salaries    3.9  \n",
       "2               ₹27L      ₹9,00,000/yr        18 salaries    3.9  \n",
       "3               ₹22L     ₹11,63,336/yr        15 salaries    4.1  \n",
       "4               ₹1Cr     ₹12,18,244/yr        15 salaries    3.9  \n",
       "5               ₹16L      ₹7,39,238/yr        14 salaries      4  \n",
       "6               ₹15L     ₹12,80,000/yr        14 salaries    3.6  \n",
       "7               ₹15L      ₹8,63,750/yr        10 salaries    4.2  \n",
       "8               ₹15L     ₹11,10,000/yr         9 salaries    3.6  \n",
       "9               ₹20L     ₹14,23,677/yr         9 salaries    3.7  \n",
       "10              ₹22L     ₹13,28,697/yr         9 salaries    3.9  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Minimum Salary(₹)\":min_sal[0:10],\"Maximum Salary(₹)\":max_sal[0:10],\"Average Salary(₹)\":avg_sal[0:10],\"Number of Salaries\":sal_num[0:10],\"Rating\":Rating[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1\n",
    "JobDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "#### 1. Brand\n",
    "#### 2. Product Description\n",
    "#### 3. Price\n",
    "#### 4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = 'https://www.flipkart.com' \n",
    "driver.get(url)\n",
    "glassessearch = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "glassessearch.send_keys(\"Sunglasses\")\n",
    "search = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "disc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "\n",
    "    for b in brand_tag:\n",
    "        brand.append(b.text)\n",
    "    for d in desc_tag :\n",
    "        desc.append(d.text)\n",
    "    for p in price_tag:\n",
    "        price.append(p.text)\n",
    "    for c in disc_tag:\n",
    "        disc.append(c.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<2):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    for c in disc_tag:\n",
    "        try:\n",
    "            disc.append(c.text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in SunglassesDF DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SunglassesDF = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Discount\":disc[0:100],\"Description\":desc[0:100],})\n",
    "SunglassesDF.reset_index(drop=True,inplace = True)\n",
    "SunglassesDF.index+= 1\n",
    "SunglassesDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAMIW COLLECTION</td>\n",
       "      <td>₹199</td>\n",
       "      <td>86% off</td>\n",
       "      <td>UV Protection Wayfarer, Sports, Shield, Rectan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>₹739</td>\n",
       "      <td>71% off</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹599</td>\n",
       "      <td>25% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹699</td>\n",
       "      <td>22% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹854</td>\n",
       "      <td>57% off</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹609</td>\n",
       "      <td>32% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹669</td>\n",
       "      <td>25% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹474</td>\n",
       "      <td>68% off</td>\n",
       "      <td>UV Protection, Gradient Wayfarer Sunglasses (55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹203</td>\n",
       "      <td>79% off</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Name Price(₹) Discount  \\\n",
       "1    HAMIW COLLECTION     ₹199  86% off   \n",
       "2               Wrogn     ₹739  71% off   \n",
       "3           Elligator     ₹295  88% off   \n",
       "4            Fastrack     ₹599  25% off   \n",
       "5            Fastrack     ₹699  22% off   \n",
       "..                ...      ...      ...   \n",
       "96          ROYAL SON     ₹854  57% off   \n",
       "97           Fastrack     ₹609  32% off   \n",
       "98           Fastrack     ₹669  25% off   \n",
       "99          ROYAL SON     ₹474  68% off   \n",
       "100         ROYAL SON     ₹203  79% off   \n",
       "\n",
       "                                           Description  \n",
       "1    UV Protection Wayfarer, Sports, Shield, Rectan...  \n",
       "2                    Mirrored Wayfarer Sunglasses (51)  \n",
       "3                  UV Protection Round Sunglasses (54)  \n",
       "4     UV Protection Rectangular Sunglasses (Free Size)  \n",
       "5        UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "..                                                 ...  \n",
       "96         UV Protection Shield Sunglasses (Free Size)  \n",
       "97       UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "98           UV Protection Rectangular Sunglasses (58)  \n",
       "99    UV Protection, Gradient Wayfarer Sunglasses (55)  \n",
       "100  Gradient, UV Protection Wayfarer Sunglasses (F...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SunglassesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.Scrape the data for first 100 reviews.\n",
    "#### 1. Rating\n",
    "#### 2. Review_summary\n",
    "#### 3. Full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace' \n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewall = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div/span')\n",
    "viewall.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_sum = []\n",
    "rating = []\n",
    "rev = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "    rev_sum_tag = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    rating_tag = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    rev_tag = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    \n",
    "\n",
    "    for r in rev_sum_tag:\n",
    "        rev_sum.append(r.text)\n",
    "    for j in rating_tag :\n",
    "        rating.append(j.text)\n",
    "    for k in rev_tag:\n",
    "        rev.append(k.text.replace(\"\\n\",\" \"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<10):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    rev_sum_tag = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    rating_tag = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    rev_tag = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for r in rev_sum_tag:\n",
    "        try:\n",
    "            rev_sum.append(r.text)\n",
    "        except:\n",
    "            pass\n",
    "    for j in rating_tag :\n",
    "        try:\n",
    "            rating.append(j.text)\n",
    "        except:\n",
    "            pass\n",
    "    for k in rev_tag:\n",
    "        try:\n",
    "            rev.append(k.text.replace(\"\\n\",\" \"))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    i=i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing values in iphoneDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphoneDF = pd.DataFrame({\"Summary\":rev_sum[0:100],\"Full Review\":rev[0:100],\"Rating\":rating[0:100]})\n",
    "iphoneDF.reset_index(drop=True,inplace = True)\n",
    "iphoneDF.index+= 1\n",
    "iphoneDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Full Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Summary                                        Full Review  \\\n",
       "1        Simply awesome  Really satisfied with the Product I received.....   \n",
       "2             Brilliant  The Best Phone for the Money  The iPhone 11 of...   \n",
       "3      Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "4             Fabulous!  This is my first iOS phone. I am very happy wi...   \n",
       "5     Worth every penny  Previously I was using one plus 3t it was a gr...   \n",
       "..                  ...                                                ...   \n",
       "96     Perfect product!  Iphone is just awesome.. battery backup is ver...   \n",
       "97   Highly recommended  It's my first time to use iOS phone and I am l...   \n",
       "98       Simply awesome  Excellent camera, good performance, no lag. Th...   \n",
       "99    Worth every penny  It’s been almost a month since I have been usi...   \n",
       "100            Terrific  Really worth of money. i just love it. It is t...   \n",
       "\n",
       "    Rating  \n",
       "1        5  \n",
       "2        5  \n",
       "3        5  \n",
       "4        5  \n",
       "5        5  \n",
       "..     ...  \n",
       "96       5  \n",
       "97       5  \n",
       "98       5  \n",
       "99       5  \n",
       "100      5  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphoneDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Full Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.  I’m am v...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.  I’m am v...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️ Its awesome mobile phone i...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Classy product</td>\n",
       "      <td>Totally in love with this ❤ the camera quality...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Summary                                        Full Review  \\\n",
       "1        Simply awesome  Really satisfied with the Product I received.....   \n",
       "2             Brilliant  The Best Phone for the Money  The iPhone 11 of...   \n",
       "3      Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "4             Fabulous!  This is my first iOS phone. I am very happy wi...   \n",
       "5     Worth every penny  Previously I was using one plus 3t it was a gr...   \n",
       "6         Great product  Amazing Powerful and Durable Gadget.  I’m am v...   \n",
       "7     Worth every penny  i11 is worthy to buy, too much happy with the ...   \n",
       "8           Good choice  So far it’s been an AMAZING experience coming ...   \n",
       "9    Highly recommended  iphone 11 is a very good phone to buy only if ...   \n",
       "10  Best in the market!  Great iPhone very snappy experience as apple k...   \n",
       "11       Simply awesome  Really satisfied with the Product I received.....   \n",
       "12            Brilliant  The Best Phone for the Money  The iPhone 11 of...   \n",
       "13     Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "14            Fabulous!  This is my first iOS phone. I am very happy wi...   \n",
       "15    Worth every penny  Previously I was using one plus 3t it was a gr...   \n",
       "16        Great product  Amazing Powerful and Durable Gadget.  I’m am v...   \n",
       "17    Worth every penny  i11 is worthy to buy, too much happy with the ...   \n",
       "18          Good choice  So far it’s been an AMAZING experience coming ...   \n",
       "19   Highly recommended  iphone 11 is a very good phone to buy only if ...   \n",
       "20  Best in the market!  Great iPhone very snappy experience as apple k...   \n",
       "21     Perfect product!  It’s a must buy who is looking for an upgrade ...   \n",
       "22     Perfect product!  Value for money❤️❤️ Its awesome mobile phone i...   \n",
       "23   Highly recommended  What a camera .....just awesome ..you can feel...   \n",
       "24       Classy product  Totally in love with this ❤ the camera quality...   \n",
       "25    Worth every penny  Best budget Iphone till date ❤️ go for it guys...   \n",
       "\n",
       "   Rating  \n",
       "1       5  \n",
       "2       5  \n",
       "3       5  \n",
       "4       5  \n",
       "5       5  \n",
       "6       5  \n",
       "7       5  \n",
       "8       4  \n",
       "9       5  \n",
       "10      5  \n",
       "11      5  \n",
       "12      5  \n",
       "13      5  \n",
       "14      5  \n",
       "15      5  \n",
       "16      5  \n",
       "17      5  \n",
       "18      4  \n",
       "19      5  \n",
       "20      5  \n",
       "21      5  \n",
       "22      5  \n",
       "23      5  \n",
       "24      5  \n",
       "25      5  "
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphoneDF.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "#### You have to scrape 4 attributes of each sneaker :\n",
    "#### 1. Brand\n",
    "#### 2. Product Description\n",
    "#### 3. Price\n",
    "#### 4. discount %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = 'https://www.flipkart.com' \n",
    "driver.get(url)\n",
    "Sneakerssearch = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "Sneakerssearch.send_keys(\"Sneakers\")\n",
    "search = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "disc = []\n",
    "brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for b in brand_tag:\n",
    "   brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "   desc.append(d.text)\n",
    "for p in price_tag:\n",
    "   price.append(p.text)\n",
    "for c in disc_tag:\n",
    "   disc.append(c.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time \n",
    "\n",
    "\n",
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<2):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    for c in disc_tag:\n",
    "        try:\n",
    "            disc.append(c.text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    \n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing values in  SneakersDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>₹1,289</td>\n",
       "      <td>65% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Echor</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "      <td>HAWK21 Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>₹378</td>\n",
       "      <td>62% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>₹240</td>\n",
       "      <td>51% off</td>\n",
       "      <td>5011-Latest Collection Stylish Casual Loafer S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹424</td>\n",
       "      <td>78% off</td>\n",
       "      <td>Casual Sneakers White Shoes For Men And Boys S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>₹499</td>\n",
       "      <td>81% off</td>\n",
       "      <td>Men &amp; Boys Stylish, Comfortable Mesh Shoes Wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>₹407</td>\n",
       "      <td>59% off</td>\n",
       "      <td>SM-162 Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>RODDICK SHOES</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "      <td>Droge IDP Sneakers For Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand Name Price(₹) Discount  \\\n",
       "1                 DUCATI   ₹1,289  65% off   \n",
       "2                  Echor     ₹599  40% off   \n",
       "3                Numenzo     ₹378  62% off   \n",
       "4    World Wear Footwear     ₹240  51% off   \n",
       "5               ASTEROID     ₹499  75% off   \n",
       "..                   ...      ...      ...   \n",
       "96                Chevit     ₹424  78% off   \n",
       "97          Robbie jones     ₹379  62% off   \n",
       "98   World Wear Footwear     ₹499  81% off   \n",
       "99               Numenzo     ₹407  59% off   \n",
       "100        RODDICK SHOES     ₹474  52% off   \n",
       "\n",
       "                                           Description  \n",
       "1                                     Sneakers For Men  \n",
       "2                              HAWK21 Sneakers For Men  \n",
       "3                                     Sneakers For Men  \n",
       "4    5011-Latest Collection Stylish Casual Loafer S...  \n",
       "5    Original Luxury Branded Fashionable Men's Casu...  \n",
       "..                                                 ...  \n",
       "96   Casual Sneakers White Shoes For Men And Boys S...  \n",
       "97   Casual , Partywear Sneakers Shoes For Men's An...  \n",
       "98   Men & Boys Stylish, Comfortable Mesh Shoes Wit...  \n",
       "99                             SM-162 Sneakers For Men  \n",
       "100                         Droge IDP Sneakers For Men  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SneakersDF = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Discount\":disc[0:100],\"Description\":desc[0:100],})\n",
    "SneakersDF.reset_index(drop=True,inplace = True)\n",
    "SneakersDF.index+= 1\n",
    "SneakersDF.shape\n",
    "\n",
    "SneakersDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: Go to the link - https://www.myntra.com/shoes\n",
    "#### Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = 'https://www.myntra.com/shoes' \n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\")\n",
    "colour_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "price_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "price2 = []\n",
    "brand_tag = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='product-price']//span[1]\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in brand_tag:\n",
    "   brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "   desc.append(d.text)\n",
    "for p in price_tag:\n",
    "   price.append(p.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "\n",
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('pagination-next')\n",
    "while(i<1):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']//span[1]\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    \n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 8999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5495',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8399Rs. 10499',\n",
       " 'Rs. 8399',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9749Rs. 14999',\n",
       " 'Rs. 9749',\n",
       " 'Rs. 5499',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6299Rs. 6999',\n",
       " 'Rs. 6299',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6299Rs. 8999',\n",
       " 'Rs. 6299',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 5499',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 5999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8099Rs. 8999',\n",
       " 'Rs. 8099',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 6299Rs. 8999',\n",
       " 'Rs. 6299',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 5999',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 10490',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 6599Rs. 10999',\n",
       " 'Rs. 6599',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5525Rs. 8500',\n",
       " 'Rs. 5525',\n",
       " '',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " '',\n",
       " 'Rs. 8399Rs. 10499',\n",
       " 'Rs. 8399',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 5990',\n",
       " '',\n",
       " 'Rs. 5525Rs. 8500',\n",
       " 'Rs. 5525',\n",
       " '',\n",
       " 'Rs. 5699',\n",
       " '',\n",
       " 'Rs. 5579Rs. 5999',\n",
       " 'Rs. 5579',\n",
       " '',\n",
       " 'Rs. 5499',\n",
       " '',\n",
       " 'Rs. 6293Rs. 8990',\n",
       " 'Rs. 6293',\n",
       " '',\n",
       " 'Rs. 6499',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " '',\n",
       " 'Rs. 5803Rs. 8290',\n",
       " 'Rs. 5803',\n",
       " '',\n",
       " 'Rs. 5490',\n",
       " '',\n",
       " 'Rs. 10399Rs. 12999',\n",
       " 'Rs. 10399',\n",
       " '',\n",
       " 'Rs. 6293Rs. 8990',\n",
       " 'Rs. 6293',\n",
       " '',\n",
       " 'Rs. 5592Rs. 6990',\n",
       " 'Rs. 5592',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 7195',\n",
       " '',\n",
       " 'Rs. 6399Rs. 7999',\n",
       " 'Rs. 6399',\n",
       " '',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 5599Rs. 7999',\n",
       " 'Rs. 5599',\n",
       " '',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 8990',\n",
       " '',\n",
       " 'Rs. 5990',\n",
       " '',\n",
       " 'Rs. 5599Rs. 6999',\n",
       " 'Rs. 5599',\n",
       " '',\n",
       " 'Rs. 7490',\n",
       " '',\n",
       " 'Rs. 6599Rs. 10999',\n",
       " 'Rs. 6599',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 6490',\n",
       " '',\n",
       " 'Rs. 6399Rs. 7999',\n",
       " 'Rs. 6399',\n",
       " '',\n",
       " 'Rs. 5990',\n",
       " '',\n",
       " 'Rs. 5990',\n",
       " '',\n",
       " 'Rs. 5990',\n",
       " '',\n",
       " 'Rs. 5599Rs. 6999',\n",
       " 'Rs. 5599',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 5490',\n",
       " '',\n",
       " 'Rs. 8990',\n",
       " '',\n",
       " 'Rs. 7006Rs. 7149',\n",
       " 'Rs. 7006',\n",
       " '',\n",
       " 'Rs. 7999',\n",
       " '',\n",
       " 'Rs. 7192Rs. 8990',\n",
       " 'Rs. 7192',\n",
       " '',\n",
       " 'Rs. 7192Rs. 8990',\n",
       " 'Rs. 7192']"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price #has duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(\"\" in price) :\n",
    "    price.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 8999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5495',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8399Rs. 10499',\n",
       " 'Rs. 8399',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9749Rs. 14999',\n",
       " 'Rs. 9749',\n",
       " 'Rs. 5499',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6299Rs. 6999',\n",
       " 'Rs. 6299',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6299Rs. 8999',\n",
       " 'Rs. 6299',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 5499',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 5999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8099Rs. 8999',\n",
       " 'Rs. 8099',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 6299Rs. 8999',\n",
       " 'Rs. 6299',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 5999',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 10490',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 6599Rs. 10999',\n",
       " 'Rs. 6599',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5525Rs. 8500',\n",
       " 'Rs. 5525',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 8399Rs. 10499',\n",
       " 'Rs. 8399',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5525Rs. 8500',\n",
       " 'Rs. 5525',\n",
       " 'Rs. 5699',\n",
       " 'Rs. 5579Rs. 5999',\n",
       " 'Rs. 5579',\n",
       " 'Rs. 5499',\n",
       " 'Rs. 6293Rs. 8990',\n",
       " 'Rs. 6293',\n",
       " 'Rs. 6499',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 5399Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 5803Rs. 8290',\n",
       " 'Rs. 5803',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 10399Rs. 12999',\n",
       " 'Rs. 10399',\n",
       " 'Rs. 6293Rs. 8990',\n",
       " 'Rs. 6293',\n",
       " 'Rs. 5592Rs. 6990',\n",
       " 'Rs. 5592',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 7195',\n",
       " 'Rs. 6399Rs. 7999',\n",
       " 'Rs. 6399',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 5599Rs. 7999',\n",
       " 'Rs. 5599',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5599Rs. 6999',\n",
       " 'Rs. 5599',\n",
       " 'Rs. 7490',\n",
       " 'Rs. 6599Rs. 10999',\n",
       " 'Rs. 6599',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6490',\n",
       " 'Rs. 6399Rs. 7999',\n",
       " 'Rs. 6399',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5599Rs. 6999',\n",
       " 'Rs. 5599',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7006Rs. 7149',\n",
       " 'Rs. 7006',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7192Rs. 8990',\n",
       " 'Rs. 7192',\n",
       " 'Rs. 7192Rs. 8990',\n",
       " 'Rs. 7192']"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicate values\n",
    "j = 0\n",
    "for c in price:\n",
    "    if len(c) > 12:\n",
    "        del price[j]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 8999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5495',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8399',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9749',\n",
       " 'Rs. 5499',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6299',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6299',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 5499',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 5999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8099',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 6299',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 5999',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 10490',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 6599',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5525',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 8399',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5525',\n",
       " 'Rs. 5699',\n",
       " 'Rs. 5579',\n",
       " 'Rs. 5499',\n",
       " 'Rs. 6293',\n",
       " 'Rs. 6499',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 5399',\n",
       " 'Rs. 5803',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 10399',\n",
       " 'Rs. 6293',\n",
       " 'Rs. 5592',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 7195',\n",
       " 'Rs. 6399',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 5599',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5599',\n",
       " 'Rs. 7490',\n",
       " 'Rs. 6599',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6490',\n",
       " 'Rs. 6399',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5990',\n",
       " 'Rs. 5599',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 5490',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7006',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7192',\n",
       " 'Rs. 7192']"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### storing the values in MyntraShoeDF DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Men Charged Bandit 6 Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 6999</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 5495</td>\n",
       "      <td>Men Crater Remixa Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Unisex Project Rock Recruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Rs. 8990</td>\n",
       "      <td>Men Textured Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>KIPRUN By Decathlon</td>\n",
       "      <td>Rs. 7006</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Women Solid Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Rs. 7192</td>\n",
       "      <td>Women Peep Toe Heels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Rs. 7192</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand Name  Price(₹)                     Description\n",
       "1            UNDER ARMOUR  Rs. 8999    Men Charged Bandit 6 Running\n",
       "2                    Puma  Rs. 6999  Men Cell Fraction Fade Running\n",
       "3                    Nike  Rs. 5495      Men Crater Remixa Sneakers\n",
       "4                    Geox  Rs. 9999       Men Leather Formal Derbys\n",
       "5            UNDER ARMOUR  Rs. 9999     Unisex Project Rock Recruit\n",
       "..                    ...       ...                             ...\n",
       "96                  Ruosh  Rs. 8990             Men Textured Derbys\n",
       "97    KIPRUN By Decathlon  Rs. 7006             Women Running Shoes\n",
       "98                   ALDO  Rs. 7999            Women Solid Sneakers\n",
       "99   Heel & Buckle London  Rs. 7192            Women Peep Toe Heels\n",
       "100  Heel & Buckle London  Rs. 7192             Women Leather Pumps\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyntraShoesDF = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Description\":desc[0:100],})\n",
    "MyntraShoesDF.reset_index(drop=True,inplace = True)\n",
    "MyntraShoesDF.index+= 1\n",
    "\n",
    "\n",
    "MyntraShoesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: Go to webpage https://www.amazon.in/\n",
    "#### Enter “Laptop” in the search field and then click the search icon.\n",
    "#### Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "#### attributes for each laptop:\n",
    "#### 1. title\n",
    "#### 2. Ratings\n",
    "#### 3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.amazon.in/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptopsearch = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "Laptopsearch.send_keys(\"Laptop\")\n",
    "search = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i7_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[7]/li[26]/span/a/span\")\n",
    "i7_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i9_filter =  driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[7]/li[28]/span/a/span\")\n",
    "i9_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "price = []\n",
    "Rating = []\n",
    "Rating_tag = driver.find_elements_by_xpath(\"//span[@class='a-icon-alt']\")\n",
    "title_tag = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='sg-col-inner']//span[@class='a-price-whole']\")\n",
    "\n",
    "for i in title_tag:\n",
    "    title.append(i.text)\n",
    "    \n",
    "for r in Rating_tag :\n",
    "    Rating.append(r.get_attribute(\"innerHTML\"))\n",
    "    \n",
    "for p in price_tag:\n",
    "    price.append(p.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del title[8] #deleting element with no price attribute to prevent price mismatch in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.2 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '3.8 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '3.8 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.5 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '3.7 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '4.8 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '5.0 out of 5 stars',\n",
       " '3.7 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '5.0 out of 5 stars',\n",
       " '3.0 out of 5 stars',\n",
       " '4 Stars &amp; Up',\n",
       " '3 Stars &amp; Up',\n",
       " '2 Stars &amp; Up',\n",
       " '1 Star &amp; Up',\n",
       " '4.2 out of 5']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving as LaptopDf DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...</td>\n",
       "      <td>1,07,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>1,09,990</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....</td>\n",
       "      <td>81,990</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>90,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>71,990</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Gaming(2021) 10th Gen Intel Core i...</td>\n",
       "      <td>1,09,990</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...</td>\n",
       "      <td>5,56,524</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>79,490</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>91,790</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lenovo Legion 5 10th Gen Intel Core i7-10750H ...</td>\n",
       "      <td>1,07,990</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Laptop Name  Price(₹)  \\\n",
       "1   ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...  1,07,990   \n",
       "2   HP Envy 11th Gen Core i7 Processor 13.3-inch (...  1,09,990   \n",
       "3   MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....    81,990   \n",
       "4   HP Pavilion (2021) Thin & Light 11th Gen Core ...    90,990   \n",
       "5   Mi Notebook Horizon Edition 14 Intel Core i7-1...    71,990   \n",
       "6   HP Pavilion Gaming(2021) 10th Gen Intel Core i...  1,09,990   \n",
       "7   ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...  5,56,524   \n",
       "8   HP Envy 11th Gen Core i7 Processor 13.3-inch (...    79,490   \n",
       "9   ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    91,790   \n",
       "10  Lenovo Legion 5 10th Gen Intel Core i7-10750H ...  1,07,990   \n",
       "\n",
       "                Rating  \n",
       "1   4.2 out of 5 stars  \n",
       "2   4.1 out of 5 stars  \n",
       "3   3.8 out of 5 stars  \n",
       "4   4.3 out of 5 stars  \n",
       "5   4.4 out of 5 stars  \n",
       "6   4.4 out of 5 stars  \n",
       "7   4.0 out of 5 stars  \n",
       "8   4.1 out of 5 stars  \n",
       "9   3.8 out of 5 stars  \n",
       "10  4.4 out of 5 stars  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LaptopDF = pd.DataFrame({\"Laptop Name\":title[0:10],\"Price(₹)\":price[0:10],\"Rating\":Rating[0:10]})\n",
    "LaptopDF.reset_index(drop=True,inplace = True)\n",
    "LaptopDF.index+= 1\n",
    "LaptopDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
